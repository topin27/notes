{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可能存在的问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 分布漂移（Distribution Drift）\n",
    "\n",
    "很多模型都是假设数据的分布是一定的，不变的，即历史数据与将来的数据都服从相同的分布。但是，在现实生活中，这种假设往往是不成立的，这种现象称为分布漂移（Distribution Drift）。因此在进行模型构建之时，我们需要去扑捉分布漂移信息并使自己的模型能够应对这种情况。一个常用的方法便是使用一些验证指标对模型在不断新生的数据集上进行性能跟踪。如果指标值能够达到模型构建时的指标值，那么表示模型能够继续对当前数据进行拟合。当性能开始下降时，说明该模型已经无法拟合当前的数据了，因此需要对模型进行重新训练了。 \n",
    "\n",
    "### 2. 超参数（hyperparameters）\n",
    "\n",
    "机器学习模型建立过程其实是一个参数学习与调优的过程。对模型进行训练，便是模型参数的学习更新过程。模型出了这些常规参数之外，还存在超参数（hyperparameters）。举例，我们在对垃圾邮件检测进行建模时，假设使用logistic回归。那么该任务就是在特征空间中寻找能够将垃圾邮件与正常邮件分开的logistic函数位置，于是模型训练的学习算法便是得到各个特征的权值，从而决定函数的位置。但是该学习算法不会告诉我们对于该任务需要使用多少个特征来对一封邮件进行表征，特征的数目这个参数便是该模型的超参数。 \n",
    "\n",
    "超参数的调优是一个相当复杂与繁琐的任务。在模型原型设计阶段，需要尝试不同的模型、不同的超参数意见不同的特征集，我们需要寻找一个最优的超参数，因此需要使用相关的搜索算法去寻找，如格搜索（grid search）、随机搜索（random search）以及启发式搜索（smart search）等。这些搜索算法是从超参数空间中寻找一个最优的值。\n",
    "\n",
    "```C\n",
    "#include <stdio.h>\n",
    "int main()\n",
    "{\n",
    "    printf(\"helo\");\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评价指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 准确率(Accuracy)\n",
    "### 2. 平均准确率(Average Per-class Accuracy)\n",
    "### 3. 对数损失函数(Log-loss)\n",
    "\n",
    "在分类输出中，若输出不再是0-1，而是实数值，即属于每个类别的概率，那么可以使用Log-loss对分类结果进行评价。Log-loss具体的数学表达式为： \n",
    "$$log\\_loss = -\\frac{1}{N}\\sum_{i=1}^{N}y_i\\log{p_i} + (1-y_i)\\log{(1-p_i)}$$\n",
    "其中，$y_i$是指第i个样本所属的真实类别0或者1，$p_i$表示第i个样本属于类别1的概率，这样上式中的两个部分对于每个样本只会选择其一，因为有一个一定为0，当预测与实际类别完全匹配时，则两个部分都是0，其中假定$0\\log{0}=0$。\n",
    "\n",
    "### 4. 精确率-召回率(Precision-Recall)\n",
    "### 5. AUC(Area under the Curve(Receiver Operating Characteristic, ROC))\n",
    "\n",
    "AUC的全称是Area under the Curve，即曲线下的面积，这条曲线便是ROC曲线，全称为the Receiver Operating Characteristic曲线。\n",
    "\n",
    "ROC曲线有个很好的特性：当测试集中的正负样本的分布变化的时候，ROC曲线能够保持不变。在实际的数据集中，经常会出现类别不平衡（class imbalance）现象，即负样本比正样本少很多（或者相反），而且测试数据集中的正负样本的分布也可能随时间发生变化。\n",
    "\n",
    "### 6. 混淆矩阵(Confusion Matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据倾斜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 类别不均衡（Imbalanced Classes）\n",
    "\n",
    "如果评价指标对待每一个类别下的每一个实例都采用相等的权值，那么就很难处理类别不平衡问题。因为此时评价指标会被数据量大的类别占主导，起决定性作用。并且不止是影响模型评价阶段，而且会影响模型的训练阶段。如果数据的类别不平衡不做处理，那么就会影响到对小类别的数据记录的分类。\n",
    "\n",
    "### 2. 异常点（Outliers）\n",
    "\n",
    "异常点是另一种数据倾斜问题。值大的异常点会对回归造成很大的影响与问题。例如，Million Song Dataset中，一个用户对一首歌曲的评分为该用户听这首歌曲的次数，回归模型的预测得分中最高得分竟然超过了16000分，这说明回归模型出现了一些问题，并且导致其它的误差相对于该误差都是极小的。我们可以使用误差的中位数来减少这个异常点所所带来的影响。从而增加鲁棒性。但是该方法不能解决在模型训练阶段的该问题。有效的解决方法是在数据预处理阶段对数据进行数据清洗从而剔除异常点，以及对人物进行重新定义与建模，使得其对异常低能不敏感。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 离线评价机制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Hold-out Validation\n",
    "\n",
    "Hold-out Validation较简单，它假设数据集中的每个数据点都是独立同分布的（i.i.d,independently and identically distributed）。因此我们只需要简单得将原数据集随机划分成两个部分，较大的部分作为训练集，用来训练数据，较小的部分作为验证集，用来对模型进行验证。 \n",
    "\n",
    "### 2. Cross-Validation\n",
    "\n",
    "Cross-Validation是另一种模型训练集与验证集的产生方法，即将数据集划分成多个小部分集合，如划分成k个部分，那么就变为了k-fold cross validation。依次使用其中的k-1个数据集对模型进行训练（每次使用k-1个不同的数据集），然后使用剩下的一个数据集对模型进行评价，计算评价指标值。接着重复前面的步骤，重复k次，得到k个评价指标值。最后计算这k个评价指标的平均值。其中k是一个超参数，我们可以尝试多个k，选择最好的平均评价指标值所对应的k为最终的k值。 \n",
    "\n",
    "### 3. Bootstrapping和Jackknife\n",
    "\n",
    "Bootstrapping是一种重采样技术，翻译成自助法。它通过采样技术从原始的单个数据集上产生多个新的数据集，每个新的数据集称为一个bootstrapped dataset，并且每个新的数据集大小与原始数据集大小相等。这样，每个新的数据集都可以用来对模型进行评价，从而可以得到多个评价值，进一步可以得到评价方差与置信区间。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超参数调优(Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 模型参数与超参数\n",
    "\n",
    "超参数的确定不是在模型的训练阶段。普通的线性回归是没有超参数的（除了特征的个数），而Ridge回归与Lasso回归都添加了正则项（Ridge岭回归加上L2正则项，Lasso回归加上L1正则项），这些正则项都需要一个正则参数（regularization parameter）。如决策树需要设置树的深度和叶子数、支持向量机（SVM）需要设置一个分类错误的惩罚因子、带核的SVM还需要设置核的参数（如RBF径向基函数的宽度）等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 超参数的作用\n",
    "\n",
    " 模型的超参数是用来干什么的呢？如正则化因子是来控制模型的能力，模型拟合数据的自由度（degrees of freedom）决定了模型的灵活度。合理的控制模型的能力能够有效得防止过拟合现象。因此为了防止过拟合的发生，需要牺牲一些精度。因此合理的设置模型的超参数则非常重要。\n",
    "  另一种类型的模型超参数来自于模型的训练阶段。模型训练是一个使损失函数（或代价函数，训练阶段的评价指标）最小化的过程，这过程会用到很多最优化技术与方法，使用的最优化方法中需要用到一些参数。如SGD（ stochastic gradient descent）中，需要一个学习速率因子、初始点以及收敛阈值等。又如，随机森林（Random Forests）和自助提升决策树（Boosted decision trees）需要设置树的个数的参数与正则化参数等等。这些超参数需要被合理地设置以找到一个好的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 超参数调优机制\n",
    "\n",
    "超参数设置的好坏对模型的评价指标值产生较大的影响。不同的数据集上面创建模型会有不同的最优超参数，因此对于不同的数据集需要各自调优。\n",
    "\n",
    "超参数的设置过程为：首先设置一个初始的超参数值，然后进行模型训练，将模型的指标反馈都超参数调优机制中，调节超参数，继续训练模型，一直进行下去，若干次后得到一个目前最优的超参数值。最后使用该最优的超参数去训练模型，并进行模型验证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 超参数调优算法\n",
    "\n",
    "  从概念上讲，超参数调优是一个最优化任务过程，就像模型训练一样。然而，这两者之间相当的不同。在模型训练中，使用一个称为代价函数的数据公式为目标去进行对模型参数进行训练调优。而在超参数调优中，无法使用一个形式化的公式为目标去进行调优，它就像一个黑盒子，需要使用模型训练结束后的模型评价结果为指导去进行调优。这就是为什么超参数调优较为困难。\n",
    "\n",
    "#### 4.1 格搜索(Grid Search)\n",
    "\n",
    "顾名思义，格搜索便是将超参数的取值范围划分成一个个格子，然后对每一个格子所对应的值进行评估，选择评估结果最好的格子所对应的超参数值。例如，对于决策树叶子节点个数这一超参数，可以将值划分为这些格子：10, 20, 30, …, 100, …；又如正则化因子这一超参数，一般使用指数值，那么可以划分为：1e-5, 1e-4 1e-3, …, 1。有时可以进行猜测对格子进行搜索去获得最优的超参数。如，当从第一个开始，发现效果较差，第二个好了一点，那么可以第三个可以取最后一个。格搜索较为简单并且可以进行并行化。\n",
    "\n",
    "#### 4.2 随机搜索(Random Search)\n",
    "\n",
    "在论文 “Random Search for Hyper Parameter Optimization” (Bergstra and Bengio)中，已经验证了随机搜索是一个简单而有效的方法。它是格搜索的变种。相比于搜索整个格空间，随机搜索只对随机采样的那些格进行计算，然后在这中间选择一个最好的。因此随机搜索比格搜索的代价低。随机搜索有个缺点，即其可能找不到最优的点。但是前面的那篇论文已经证明，随机采样60个点的性能已经足够好了。从概率的角度来说，对于任何的分布的样本空间若存在最大值，那么随机采样60个点中的最大值位于整个样本空间top5%的值的集合中的概率达到95%。\n",
    "\n",
    "#### 4.3 智能搜索(Smart Search)\n",
    "\n",
    "相对于前面的两种方法，智能搜索算法最大的缺点便是不能并行化。它的处理过程是一个序列，并只处理一部分候选点，然后对当前点进行评估，决定下一个点。智能搜索的目的是只对一部分点进行评估从而节省调优时间。\n",
    "\n",
    "可以看出，智能搜索需要时间去计算下一个评估的点，于是相对于前面的方法，可能需要更多的时间。因此只有在对点进行评估所用的时间大于决定下一个需要评估的点的时间时才有意义。当然智能搜索算法也需要自己的超参数，因此也需要调优。有时好的智能搜索算法超参数可以确保智能搜索快于随机搜索。\n",
    "\n",
    "目前有超参数三个智能调优算法：derivative-free optimization, Bayesian optimization和random forest smart tuning。derivative-free优化算法采用启发式来决定下一个计算的点；Bayesian和random forest优化算法都是创建一个响应函数曲面模型，由模型决定下一步需要计算的点。\n",
    "\n",
    "#### 4.4 嵌套交叉校验(Nested Cross-Validation)\n",
    "\n",
    "嵌套交叉校验又称为嵌套超参数调优。模型选择与超参数调优的不同之处在于：模型选择不仅包括对某个模型的参数进行调优（如决策树的深度），并且包括对不同模型的选择（如分类中，选择决策树还是SVM）。嵌套交叉校验即在进行某个模型训练后，需要对该模型进行交叉校验，然后将结果反馈到超参数调优机制中，对超参数调优，并使用更新后的超参数继续训练模型，一直迭代下去，知道满足一定的要求，同时对其它模型也需要如此进行训练，最后在所有训练好的模型选择一个综合各方面因素最优的模型。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
